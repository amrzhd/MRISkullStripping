{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrzhd/MRISkullStripping-/blob/main/MRI_Skull_Stripping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN1J4XX6c-T6"
      },
      "source": [
        "#MRI Skull Stripping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSYk9tVFEmPx"
      },
      "source": [
        "#Installing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woCNnWJTEsMu",
        "outputId": "45cecc89-b42d-4a14-bf4a-4bff6fdf9ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel) (71.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nibabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxXm35cmEpAE",
        "outputId": "c0a4744a-1eec-4ee1-b006-e36b704a3953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nilearn\n",
            "  Downloading nilearn-0.10.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nilearn) (4.9.4)\n",
            "Requirement already satisfied: nibabel>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (5.0.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nilearn) (24.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from nilearn) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=4.0.0->nilearn) (71.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->nilearn) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->nilearn) (2024.7.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->nilearn) (1.16.0)\n",
            "Downloading nilearn-0.10.4-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nilearn\n",
            "Successfully installed nilearn-0.10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install nilearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWnT95HhifZk",
        "outputId": "af8ce51c-4198-478c-ad03-6bb49d71e851"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.9->monai)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
            "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "Successfully installed monai-1.3.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im4aucsWdm-E"
      },
      "source": [
        "#Libraries Used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YXO5dMRWdsN2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# NI\n",
        "import nibabel as nib\n",
        "from nilearn.image import smooth_img, resample_to_img\n",
        "from nilearn.masking import apply_mask\n",
        "\n",
        "# Monai\n",
        "import monai\n",
        "from monai.transforms import (Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd,\n",
        "                              ResizeWithPadOrCropd, RandAxisFlipd, RandGaussianNoised, RandGibbsNoised)\n",
        "from monai.data import Dataset, DataLoader\n",
        "from monai.data.utils import pad_list_data_collate\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracting Data"
      ],
      "metadata": {
        "id": "KP4vzF-gyQBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your actual shareable link\n",
        "shareable_link = 'https://drive.google.com/file/d/1AdTZhhsSkyn2vp_nn-pO0UisQZPQD1O8/view?usp=sharing'\n",
        "\n",
        "# Extract file ID from the shareable link\n",
        "file_id = shareable_link.split('/d/')[1].split('/view')[0]\n",
        "\n",
        "# Create the direct download link\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}&export=download'\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = 'CC_359.zip'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(download_url, output_file, quiet=False)"
      ],
      "metadata": {
        "id": "k34swcSayS31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "25318501-b02a-44f8-8974-4891d0c91902"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1AdTZhhsSkyn2vp_nn-pO0UisQZPQD1O8&export=download\n",
            "From (redirected): https://drive.google.com/uc?id=1AdTZhhsSkyn2vp_nn-pO0UisQZPQD1O8&export=download&confirm=t&uuid=cb7351ee-36df-40fa-9075-ca89df66d36b\n",
            "To: /content/CC_359.zip\n",
            "100%|██████████| 202M/202M [00:03<00:00, 51.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CC_359.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/CC_359.zip"
      ],
      "metadata": {
        "id": "hqfkFuBJy71_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39cdfef-a725-4cec-88b2-58b5ce69cbb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/CC_359.zip\n",
            "   creating: CC_359/\n",
            "   creating: CC_359/data/\n",
            "  inflating: CC_359/data/CC0001_philips_15_55_M.nii.gz  \n",
            "  inflating: CC_359/data/CC0001_philips_15_55_M_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0002_philips_15_56_M.nii.gz  \n",
            "  inflating: CC_359/data/CC0002_philips_15_56_M_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0003_philips_15_63_F.nii.gz  \n",
            "  inflating: CC_359/data/CC0003_philips_15_63_F_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0004_philips_15_67_M.nii.gz  \n",
            "  inflating: CC_359/data/CC0004_philips_15_67_M_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0005_philips_15_62_M.nii.gz  \n",
            "  inflating: CC_359/data/CC0005_philips_15_62_M_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0006_philips_15_63_F.nii.gz  \n",
            "  inflating: CC_359/data/CC0006_philips_15_63_F_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0007_philips_15_62_M.nii.gz  \n",
            "  inflating: CC_359/data/CC0007_philips_15_62_M_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0008_philips_15_60_F.nii.gz  \n",
            "  inflating: CC_359/data/CC0008_philips_15_60_F_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0009_philips_15_69_M.nii.gz  \n",
            "  inflating: CC_359/data/CC0009_philips_15_69_M_neg.nii.gz  \n",
            "  inflating: CC_359/data/CC0010_philips_15_69_F.nii.gz  \n",
            "  inflating: CC_359/data/CC0010_philips_15_69_F_neg.nii.gz  \n",
            "   creating: CC_359/masks/\n",
            "  inflating: CC_359/masks/CC0001_philips_15_55_M_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0001_philips_15_55_M_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0002_philips_15_56_M_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0002_philips_15_56_M_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0003_philips_15_63_F_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0003_philips_15_63_F_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0004_philips_15_67_M_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0004_philips_15_67_M_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0005_philips_15_62_M_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0005_philips_15_62_M_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0006_philips_15_63_F_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0006_philips_15_63_F_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0007_philips_15_62_M_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0007_philips_15_62_M_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0008_philips_15_60_F_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0008_philips_15_60_F_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0009_philips_15_69_M_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0009_philips_15_69_M_staple_neg.nii.gz  \n",
            "  inflating: CC_359/masks/CC0010_philips_15_69_F_staple.nii.gz  \n",
            "  inflating: CC_359/masks/CC0010_philips_15_69_F_staple_neg.nii.gz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paths to the data and masks directories\n",
        "data_dir = '/content/CC_359/data/'\n",
        "mask_dir = '/content/CC_359/masks/'\n",
        "\n",
        "# Mapping of group IDs to their corresponding numbers\n",
        "group_numbers = {\n",
        "    'CC0001': '55',\n",
        "    'CC0002': '56',\n",
        "    'CC0003': '63',\n",
        "    'CC0004': '67',\n",
        "    'CC0005': '62',\n",
        "    'CC0006': '63',\n",
        "    'CC0007': '62',\n",
        "    'CC0008': '60',\n",
        "    'CC0009': '69',\n",
        "    'CC0010': '69'\n",
        "}\n",
        "\n",
        "# Lists to store image and mask file paths\n",
        "data_list = []\n",
        "\n",
        "# Function to check file existence and return paths\n",
        "def check_and_add(image_path, mask_path):\n",
        "    if os.path.exists(image_path) and os.path.exists(mask_path):\n",
        "        data_list.append({\"img\": image_path, \"brain_mask\": mask_path})\n",
        "\n",
        "# Loop through all groups from CC0001 to CC0010\n",
        "for i in range(1, 11):\n",
        "    group_id = f'CC{i:04d}'  # Group IDs (e.g., CC0001, CC0002, ..., CC0010)\n",
        "    num = group_numbers[group_id]\n",
        "\n",
        "    # Filenames for both M and F possibilities\n",
        "    image_filename_M = f'{group_id}_philips_15_{num}_M.nii.gz'\n",
        "    image_filename_F = f'{group_id}_philips_15_{num}_F.nii.gz'\n",
        "    image_neg_filename_M = f'{group_id}_philips_15_{num}_M_neg.nii.gz'\n",
        "    image_neg_filename_F = f'{group_id}_philips_15_{num}_F_neg.nii.gz'\n",
        "\n",
        "    mask_filename_M = f'{group_id}_philips_15_{num}_M_staple.nii.gz'\n",
        "    mask_filename_F = f'{group_id}_philips_15_{num}_F_staple.nii.gz'\n",
        "    mask_neg_filename_M = f'{group_id}_philips_15_{num}_M_staple_neg.nii.gz'\n",
        "    mask_neg_filename_F = f'{group_id}_philips_15_{num}_F_staple_neg.nii.gz'\n",
        "\n",
        "    # Full paths\n",
        "    image_path_M = os.path.join(data_dir, image_filename_M)\n",
        "    image_path_F = os.path.join(data_dir, image_filename_F)\n",
        "    image_neg_path_M = os.path.join(data_dir, image_neg_filename_M)\n",
        "    image_neg_path_F = os.path.join(data_dir, image_neg_filename_F)\n",
        "\n",
        "    mask_path_M = os.path.join(mask_dir, mask_filename_M)\n",
        "    mask_path_F = os.path.join(mask_dir, mask_filename_F)\n",
        "    mask_neg_path_M = os.path.join(mask_dir, mask_neg_filename_M)\n",
        "    mask_neg_path_F = os.path.join(mask_dir, mask_neg_filename_F)\n",
        "\n",
        "    # Check and add valid image-mask pairs\n",
        "    check_and_add(image_path_M, mask_path_M)\n",
        "    check_and_add(image_neg_path_M, mask_neg_path_M)\n",
        "    check_and_add(image_path_F, mask_path_F)\n",
        "    check_and_add(image_neg_path_F, mask_neg_path_F)\n",
        "\n",
        "# Split data into training (80%) and testing (20%)\n",
        "train_data, test_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the transformations using MONAI\n",
        "transforms = Compose([\n",
        "    LoadImaged(keys=[\"img\", \"brain_mask\"]),\n",
        "    EnsureChannelFirstd(keys=[\"img\", \"brain_mask\"]),\n",
        "    ScaleIntensityd(keys=[\"img\"], minv=0.0, maxv=1.0),\n",
        "    ResizeWithPadOrCropd(keys=[\"img\", \"brain_mask\"], spatial_size=(128, 128, 128)),  # Adjust the size as needed\n",
        "    RandAxisFlipd(keys=[\"img\", \"brain_mask\"], prob=0.2),\n",
        "    RandGaussianNoised(keys=[\"img\"], prob=0.2, mean=0.0, std=0.05),\n",
        "    RandGibbsNoised(keys=[\"img\"], prob=0.2, alpha=(0.1, 0.6))\n",
        "])\n",
        "\n",
        "# Create MONAI Datasets\n",
        "train_dataset = monai.data.CacheDataset(data=train_data, transform=transforms)\n",
        "test_dataset = monai.data.CacheDataset(data=test_data, transform=transforms)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,  # Batch size of 32 for training\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_list_data_collate,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,  # Batch size of 1 for testing\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=pad_list_data_collate,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# Function to print sample dimensions\n",
        "def print_sample_dimensions(dataset, num_samples=1):\n",
        "    for i in range(num_samples):\n",
        "        sample = dataset[i]\n",
        "        img = sample['img']\n",
        "        brain_mask = sample['brain_mask']\n",
        "        print(f\"Sample {i+1} dimensions:\")\n",
        "        print(f\"Image dimensions: {img.shape}\")\n",
        "        print(f\"Mask dimensions: {brain_mask.shape}\")\n",
        "\n",
        "# Print dimensions of a few samples from train and test datasets\n",
        "print(\"Train dataset sample dimensions:\")\n",
        "print_sample_dimensions(train_dataset, num_samples=1)\n",
        "\n",
        "print(\"\\nTest dataset sample dimensions:\")\n",
        "print_sample_dimensions(test_dataset, num_samples=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuo0S2ERELJC",
        "outputId": "35c72010-88e7-43c1-f2fc-4a0a6b1ed057"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 16/16 [00:14<00:00,  1.14it/s]\n",
            "Loading dataset: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset sample dimensions:\n",
            "Sample 1 dimensions:\n",
            "Image dimensions: torch.Size([1, 128, 128, 128])\n",
            "Mask dimensions: torch.Size([1, 128, 128, 128])\n",
            "\n",
            "Test dataset sample dimensions:\n",
            "Sample 1 dimensions:\n",
            "Image dimensions: torch.Size([1, 128, 128, 128])\n",
            "Mask dimensions: torch.Size([1, 128, 128, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Class"
      ],
      "metadata": {
        "id": "fgQu4XwLtkRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainModel():\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def train_model(self, model, train_loader, learning_rate=0.001, batch_size=8, epochs=50):\n",
        "        model = model.to(self.device)\n",
        "        criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss with logits\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Training loop\n",
        "        highest_train_dice = 0.0\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            dice_score_total = 0.0\n",
        "            total_batches = len(train_loader)\n",
        "\n",
        "            for inputs, masks in train_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                masks = masks.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, masks)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                # Dice Score Calculation\n",
        "                dice_score = self.dice_coefficient(outputs, masks)\n",
        "                dice_score_total += dice_score\n",
        "\n",
        "            epoch_loss = running_loss / total_batches\n",
        "            epoch_dice = dice_score_total / total_batches\n",
        "\n",
        "            if epoch_dice > highest_train_dice:\n",
        "                highest_train_dice = epoch_dice\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Dice Score: {epoch_dice:.4f}\")\n",
        "\n",
        "        print(\"Highest Train Dice Score:\", highest_train_dice)\n",
        "\n",
        "        # Save model\n",
        "        torch.save(model.state_dict(), 'unet_model.pth')\n",
        "        return model\n",
        "\n",
        "    def dice_coefficient(self, outputs, masks):\n",
        "        smooth = 1e-6\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        outputs = (outputs > 0.5).float()\n",
        "        intersection = (outputs * masks).sum(dim=(2, 3))\n",
        "        union = outputs.sum(dim=(2, 3)) + masks.sum(dim=(2, 3))\n",
        "        dice = (2. * intersection + smooth) / (union + smooth)\n",
        "        return dice.mean().item()"
      ],
      "metadata": {
        "id": "sY1PtwHotnM7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluating Class"
      ],
      "metadata": {
        "id": "apnzEELktoPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvalModel():\n",
        "    def __init__(self, model):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model.to(self.device)\n",
        "\n",
        "    def test_model(self, test_loader):\n",
        "        self.model.eval()\n",
        "        dice_score_total = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, masks in test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                masks = masks.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "\n",
        "                # Dice Score Calculation\n",
        "                dice_score = self.dice_coefficient(outputs, masks)\n",
        "                dice_score_total += dice_score\n",
        "\n",
        "        average_dice_score = dice_score_total / len(test_loader)\n",
        "        print(\"/------------------------------/\")\n",
        "        print(f\"Test Dice Score: {average_dice_score:.4f}\")\n",
        "        print(\"/------------------------------/\")\n",
        "        return average_dice_score\n",
        "\n",
        "    def dice_coefficient(self, outputs, masks):\n",
        "        smooth = 1e-6\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        outputs = (outputs > 0.5).float()\n",
        "        intersection = (outputs * masks).sum(dim=(2, 3))\n",
        "        union = outputs.sum(dim=(2, 3)) + masks.sum(dim=(2, 3))\n",
        "        dice = (2. * intersection + smooth) / (union + smooth)\n",
        "        return dice.mean().item()\n"
      ],
      "metadata": {
        "id": "rAtRibeftp7d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UNet3D Model"
      ],
      "metadata": {
        "id": "76gu36PtyOSK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-ixQbzb-XQO"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_block(x)\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.dconv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        dconv = self.dconv(x)\n",
        "        pool = self.pool(dconv)\n",
        "        return dconv, pool\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.dconv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x1 = torch.cat([x1, x2], dim=1)  # Concatenate along the channel dimension\n",
        "        x1 = self.dconv(x1)\n",
        "        return x1\n",
        "\n",
        "class UNet3DModel(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet3D, self).__init__()\n",
        "        # Encoder (Down Sampling Path)\n",
        "        self.enc1 = DownSample(in_channels, 64)\n",
        "        self.enc2 = DownSample(64, 128)\n",
        "        self.enc3 = DownSample(128, 256)\n",
        "        self.enc4 = DownSample(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        # Decoder (Up Sampling Path)\n",
        "        self.up4 = UpSample(1024, 512)\n",
        "        self.up3 = UpSample(512, 256)\n",
        "        self.up2 = UpSample(256, 128)\n",
        "        self.up1 = UpSample(128, 64)\n",
        "\n",
        "        # Output Layer\n",
        "        self.out_conv = nn.Conv3d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1, pool1 = self.enc1(x)\n",
        "        enc2, pool2 = self.enc2(pool1)\n",
        "        enc3, pool3 = self.enc3(pool2)\n",
        "        enc4, pool4 = self.enc4(pool3)\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(pool4)\n",
        "\n",
        "        # Decoder\n",
        "        up4 = self.up4(bottleneck, enc4)\n",
        "        up3 = self.up3(up4, enc3)\n",
        "        up2 = self.up2(up3, enc2)\n",
        "        up1 = self.up1(up2, enc1)\n",
        "\n",
        "        # Output Layer\n",
        "        out = self.out_conv(up1)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Summery"
      ],
      "metadata": {
        "id": "QIURp6o2rTqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (1, 128, 128, 128)\n",
        "unet3d_model = UNet3DModel().to(device)\n",
        "summary(unet3d_model, input_size)"
      ],
      "metadata": {
        "id": "D1X2ZfhRrWPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Model"
      ],
      "metadata": {
        "id": "Mef5bPrVv34s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet3d_model = UNet3DModel().to(device)\n",
        "\n",
        "# Training Hyperparameters\n",
        "EPOCHS = 500\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "unet3d_model = train_model(unet3d_model, train_loader,\n",
        "                                           learning_rate=LEARNING_RATE, epochs=EPOCHS)\n",
        "torch.save(trained_unet3d_model.state_dict(), 'unet3d_model.pth')\n"
      ],
      "metadata": {
        "id": "-Pap_0F9v6se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating Model"
      ],
      "metadata": {
        "id": "V8hcHGl_v7mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model = EvalModel(trained_unet3d_model)\n",
        "test_accuracy = eval_model.test_model(test_loader)"
      ],
      "metadata": {
        "id": "1QPUscYev_d8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y8ii9vrX-Vtu"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyO62pBVrzdxGCx8KVAfHQBN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}